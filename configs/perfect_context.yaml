number_of_questions: 1
output_file: "perfect_context_evaluation"
models:
  - name: "llama-3.1-8b-instant"
  - name: "llama-3.3-70b-versatile"